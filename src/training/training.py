# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PDC9OCjVf1ySSLVZVICnuojCs_ExLHSX
"""

!pip install datasets

!pip install -q git+https://github.com/huggingface/transformers.git

!pip install -q pytorch-lightning

# download, decompress the data
!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip
!unzip balloon_dataset.zip > /dev/null

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/woctezuma/VIA2COCO
# %cd VIA2COCO/
!git checkout fixes

import convert as via2coco

data_path = '/content/balloon/'

first_class_index = 0

for keyword in ['train', 'val']:

  input_dir = data_path + keyword + '/'
  input_json = input_dir + 'via_region_data.json'
  categories = ['balloon']
  super_categories = ['N/A']
  output_json = input_dir + 'custom_' + keyword + '.json'

  print('Converting {} from VIA format to COCO format'.format(input_json))

  coco_dict = via2coco.convert(
      imgdir=input_dir,
      annpath=input_json,
      categories=categories,
      super_categories=super_categories,
      output_file_name=output_json,
      first_class_index=first_class_index,
  )











from huggingface_hub import login
import pytorch_lightning as pl
from transformers import AutoFeatureExtractor, AutoModelForObjectDetection
import torch
from torch.utils.data import DataLoader
from datasets import load_dataset
import torchvision.transforms as transforms
from PIL import Image
import numpy as np

login()

ds = load_dataset("franperic/synth_datamatrix_docmatix_subset")

# Define id2label mapping (we only have one class - DataMatrix)
id2label = {0: "DataMatrix"}
label2id = {"DataMatrix": 0}

# Initialize feature extractor
feature_extractor = AutoFeatureExtractor.from_pretrained(
    "hustvl/yolos-small",
    size=512,  # You can adjust these parameters based on your needs
    max_size=864
)

# Create transform to convert PIL images to tensors
transform = transforms.Compose([
    transforms.ToTensor(),
])

def collate_fn(batch):
    # Convert PIL images to tensors
    pixel_values = []
    for item in batch:
        if isinstance(item["image"], Image.Image):
            img_tensor = transform(item["image"])
            pixel_values.append(img_tensor)
        else:
            pixel_values.append(item["image"])

    # Pad and stack the images
    encoding = feature_extractor.pad(pixel_values, return_tensors="pt")

    # Convert bounding boxes to DETR format
    labels = []
    for item in batch:
        bbox = item["labels"]  # Your bbox is [x1, y1, x2, y2]
        # Convert to COCO format [x, y, width, height]
        width = bbox[2] - bbox[0]
        height = bbox[3] - bbox[1]
        x = bbox[0]
        y = bbox[1]

        labels.append({
            "boxes": torch.tensor([[x, y, width, height]]),
            "class_labels": torch.tensor([0]),  # Changed from "labels" to "class_labels"
            "image_id": torch.tensor([0]),
            "area": torch.tensor([width * height]),
            "iscrowd": torch.tensor([0]),
            "orig_size": torch.tensor([item["image"].height, item["image"].width]),  # Add original image size
            "size": torch.tensor([item["image"].height, item["image"].width]),  # Add current image size
        })

    batch = {}
    batch['pixel_values'] = encoding['pixel_values']
    batch['labels'] = labels
    return batch

train_dataloader = DataLoader(
    ds["train"],
    collate_fn=collate_fn,
    batch_size=1,
    shuffle=True
)
val_dataloader = DataLoader(
    ds["val"],
    collate_fn=collate_fn,
    batch_size=1
)

# Define the model
class Detr(pl.LightningModule):
    def __init__(self, lr=2.5e-5, weight_decay=1e-4):
        super().__init__()
        # replace COCO classification head with custom head for single class
        self.model = AutoModelForObjectDetection.from_pretrained(
            "hustvl/yolos-small",
            num_labels=len(id2label),
            ignore_mismatched_sizes=True
        )
        self.lr = lr
        self.weight_decay = weight_decay

    def forward(self, pixel_values):
        outputs = self.model(pixel_values=pixel_values)
        return outputs

    def common_step(self, batch, batch_idx):
        pixel_values = batch["pixel_values"]
        labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch["labels"]]

        outputs = self.model(pixel_values=pixel_values, labels=labels)

        loss = outputs.loss
        loss_dict = outputs.loss_dict

        return loss, loss_dict

    def training_step(self, batch, batch_idx):
        loss, loss_dict = self.common_step(batch, batch_idx)
        self.log("training_loss", loss)
        for k,v in loss_dict.items():
            self.log("train_" + k, v.item())
        return loss

    def validation_step(self, batch, batch_idx):
        loss, loss_dict = self.common_step(batch, batch_idx)
        self.log("validation_loss", loss)
        for k,v in loss_dict.items():
            self.log("validation_" + k, v.item())
        return loss

    def configure_optimizers(self):
        optimizer = torch.optim.AdamW(
            self.parameters(),
            lr=self.lr,
            weight_decay=self.weight_decay
        )
        return optimizer

    def train_dataloader(self):
        return train_dataloader

    def val_dataloader(self):
        return val_dataloader

# Train the model
model = Detr()
trainer = pl.Trainer(
    accelerator="gpu",
    devices=1,
    max_steps=2000,
    gradient_clip_val=0.1,
    accumulate_grad_batches=4
)
trainer.fit(model)

import os
repo_name = "franperic/yolos-datamatrix"  # replace with your desired model name

# Create a temporary directory to save the model
output_dir = "yolos_datamatrix_model"
os.makedirs(output_dir, exist_ok=True)

# Get the trained model (the actual YOLOS model, not the Lightning module)
trained_model = model.model  # model is your Detr Lightning module
trained_model.config.id2label = id2label
trained_model.config.label2id = label2id

# Save the model and feature extractor
trained_model.save_pretrained(output_dir)
feature_extractor.save_pretrained(output_dir)

# Create a model card
model_card = """
---
language: en
tags:
- object-detection
- yolos
- datamatrix
datasets:
- custom
license: apache-2.0
---

# YOLOS DataMatrix Detector

This model is a fine-tuned version of YOLOS-small for detecting DataMatrix codes in documents.
"""

with open(os.path.join(output_dir, "README.md"), "w") as f:
    f.write(model_card)

# Push to hub
trained_model.push_to_hub(repo_name, use_auth_token=True)
feature_extractor.push_to_hub(repo_name, use_auth_token=True)

# Verify the upload
from transformers import AutoModelForObjectDetection, AutoFeatureExtractor

# Try loading the model back (optional verification step)
try:
    loaded_model = AutoModelForObjectDetection.from_pretrained(repo_name)
    loaded_feature_extractor = AutoFeatureExtractor.from_pretrained(repo_name)
    print("Successfully pushed and verified model!")
except Exception as e:
    print(f"Error verifying model: {e}")

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir lightning_logs

